{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#create the dummy Datasets"
      ],
      "metadata": {
        "id": "ZVMPZ8nS7W-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Building"
      ],
      "metadata": {
        "id": "vyaHhdxpLNf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#for classification\n",
        "# 2D array X with 100 rows and 5 columns.Each element in X is a random\n",
        "# float number between 0 and 1, generated from a uniform distribution.\n",
        "X, y_classification = np.random.rand(100, 5), np.random.randint(0, 2, size=100)\n",
        "\n",
        "#for regression\n",
        "#This line generates a 1D array y_classification containing 100 integers.\n",
        "#Each integer is randomly chosen from the set {0, 1}.\n",
        "\n",
        "y_regression = np.random.rand(100)\n",
        "\n"
      ],
      "metadata": {
        "id": "h3sHVOc_78gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(1)train_test_split () =>\n",
        "Use the function to split your data into training and testing sets"
      ],
      "metadata": {
        "id": "-3pSks789dxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split the dataset into training and testing sets\n",
        "#The test_size=0.2 => parameter indicates that 20% of the data will be reserved for testing, while the remaining 80% will be used for training\n",
        "#random_state=42  => ensures that the data is split in the same way every time the code is run, allowing for reproducible results.\n",
        "\n",
        "X_train, X_test, y_train_classification, y_test_classification = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "g9Zjy-gN9hB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(2) Linear Regression () =>\n",
        "-The LinearRegression() function in Python helps create a model that finds the best-fit straight line through your data.\n",
        "\n",
        "-In short, it helps to predict a future outcome based on past data by learning a simple line equation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hBO1b1Og_USA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#LinearRegression class is being created and stored in the variable lin_reg.\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "#X_train_reg =>  represents the independent variable(s) of the training dataset.\n",
        "#y_train_reg =>  represents the dependent variable in the training dataset.\n",
        "#The fit() =>  method trains the linear regression model on the training data.\n",
        "\n",
        "lin_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "#retrieves the coefficients of the linear regression model using the coef_ attribute.\n",
        "print(\"Linear Regression Coefficients:\", lin_reg.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YkmhJmDABDQ",
        "outputId": "ad4526a4-6a47-4d27-b7eb-6e27d86b81c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Coefficients: [ 0.0313198   0.03755143 -0.0778522  -0.11894204  0.18818602]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(3)LogisticRegression () =>\n",
        "The LogisticRegression() function in Python is used to create a model that predicts the probability of a binary outcome (like yes/no or 0/1) based on input data."
      ],
      "metadata": {
        "id": "Uz0u6VTDBTQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# creates an instance of the LogisticRegression class and stores it in the variable log_reg.\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "#X_train represents => (independent variables) of the training dataset.\n",
        "#y_train_classification represents => (dependent variable),\n",
        "\n",
        "log_reg.fit(X_train, y_train_classification)\n",
        "print(\"Logistic Regression Coefficients:\", log_reg.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbr_3nA2Bsyo",
        "outputId": "5da1c398-50da-45b8-e70d-0fd09b2fef41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Coefficients: [[-0.35257797 -0.26603844 -0.26947525  0.09471063  0.48061701]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(4)DecisionTreeClassifier () =>\n",
        "-creates a model that makes decisions to classify data into categories.\n",
        "\n",
        "-It uses a tree-like structure where:\n",
        "\n",
        "-Nodes represent decisions based on input features.\n",
        "Branches lead to  final classifications."
      ],
      "metadata": {
        "id": "NEY4heg7CGh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train_classification)\n",
        "\n",
        "#This line checks how good the decision tree model is at making predictions and shows the result.\n",
        "#X_test: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_classification: This is the real answers for the new data.\n",
        "\n",
        "print(\"Decision Tree Classifier Score:\", dt_classifier.score(X_test, y_test_classification))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNTgcTU7Cxo1",
        "outputId": "1d3394d2-04cb-4f04-a219-e86e3f323456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Score: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(5) DecisionTreeRegressor () =>\n",
        "-DecisionTreeRegressor() is a tool that predicts numbers, like house prices, using a tree-like structure that makes decisions based on input features"
      ],
      "metadata": {
        "id": "T3BQyewmC_XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dt_regressor = DecisionTreeRegressor()\n",
        "\n",
        "#X_test_reg: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_reg: This is the real answers for the new data.\n",
        "dt_regressor.fit(X_train_reg, y_train_reg)\n",
        "print(\"Decision Tree Regressor Score:\", dt_regressor.score(X_test_reg, y_test_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT7xnYebDIjL",
        "outputId": "7289d6d3-955c-47bf-e343-bc0571a127ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor Score: 0.43063684750307774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(6)RandomForestClassifier () =>\n",
        "-machine learning model that combines multiple decision trees to improve classification accuracy.\n",
        "\n",
        "- It works by creating a \"forest\" of decision trees, each trained on different random samples of the data, and then takes a majority vote to make predictions."
      ],
      "metadata": {
        "id": "AcxHg1E-D17R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(X_train, y_train_classification)\n",
        "\n",
        "#X_test: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_classification: This is the real answers for the new data.\n",
        "print(\"Random Forest Classifier Score:\", rf_classifier.score(X_test, y_test_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB2Dicp5EBLF",
        "outputId": "3c33aff0-891c-41dd-b12f-fd991318add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Score: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(7)RandomForestRegressor () =>\n",
        "-machine learning model used to predict continuous values by combining the predictions of multiple decision trees.\n",
        "\n",
        "-It creates a \"forest\" of trees, each trained on random samples of the data, and averages their predictions to improve accuracy and reduce"
      ],
      "metadata": {
        "id": "5uZF0UkFEiOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_regressor = RandomForestRegressor()\n",
        "rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "#X_test_reg: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_reg: This is the real answers for the new data.\n",
        "print(\"Random Forest Regressor Score:\", rf_regressor.score(X_test_reg, y_test_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsJqE5nrEm8g",
        "outputId": "f28ea173-a6a3-4823-eafd-10510309710e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Score: 0.3031393436329737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8) GradientBoostingClassifier () =>\n",
        "-machine learning model that combines many simple decision trees to make predictions about categories (like spam or not spam).\n",
        "\n",
        "-It builds these trees one after the other, and each new tree tries to fix the mistakes made by the previous ones, which helps improve the overall accuracy of the model"
      ],
      "metadata": {
        "id": "KHCcvSwIFFce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb_classifier = GradientBoostingClassifier()\n",
        "gb_classifier.fit(X_train, y_train_classification)\n",
        "\n",
        "#X_test: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_classification: This is the real answers for the new data.\n",
        "print(\"Gradient Boosting Classifier Score:\", gb_classifier.score(X_test, y_test_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHEk6Fr6FfxM",
        "outputId": "0583c657-5607-41f7-b4c4-9ad46ff51c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier Score: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(9) GradientBoostingRegressor() =>\n",
        "-machine learning model used for predicting continuous values, such as prices or temperatures.\n",
        "\n",
        "- It builds multiple simple decision trees in sequence, where each new tree aims to correct the errors made by the previous ones."
      ],
      "metadata": {
        "id": "W_v7poSeGA43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_classifier = GradientBoostingClassifier()\n",
        "gb_classifier.fit(X_train, y_train_classification)\n",
        "\n",
        "#X_test: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_classification: This is the real answers for the new data.\n",
        "print(\"Gradient Boosting Classifier Score:\", gb_classifier.score(X_test, y_test_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLecsgxQGRzn",
        "outputId": "d0e3a434-66d7-47d5-ecde-52820c1ffa98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier Score: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(10)GradientBoostingRegressor() =>\n",
        "-machine learning model used for predicting continuous values, such as prices or temperatures.\n",
        "\n",
        "- It builds multiple simple decision trees in sequence, where each new tree aims to correct the errors made by the previous ones."
      ],
      "metadata": {
        "id": "7DOfueHeGpY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_classifier = GradientBoostingClassifier()\n",
        "gb_classifier.fit(X_train, y_train_classification)\n",
        "\n",
        "#X_test: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_classification: This is the real answers for the new data.\n",
        "print(\"Gradient Boosting Classifier Score:\", gb_classifier.score(X_test, y_test_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cNtSIBigG24o",
        "outputId": "3885f324-ebfb-4ff5-f223-5cb31e62d3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e46bc674468d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgb_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_classification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#X_test: This is the new data (features) that the model hasn't seen before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(11)Support Vector Classifier() =>\n",
        "-machine learning model used for classification tasks.\n",
        "\n",
        "-It works by finding the best boundary (or hyperplane) that separates different categories in the data."
      ],
      "metadata": {
        "id": "-fd9St0hHA3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train_classification)\n",
        "\n",
        "#X_test: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_classification: This is the real answers for the new data.\n",
        "print(\"Support Vector Classifier Score:\", svc.score(X_test, y_test_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmmL8V4tHHwu",
        "outputId": "197bbac2-3622-46f1-bcbf-149750ad7560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Classifier Score: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(12) Support Vector Regression() =>\n",
        "-machine learning model used for predicting continuous values.\n",
        "\n",
        "- It extends the concept of Support Vector Classifier (SVC) to regression tasks by finding a function that approximates the data while allowing for some errors."
      ],
      "metadata": {
        "id": "LHxgIEPBH1Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "# Support Vector Regressor\n",
        "svr = SVR()\n",
        "svr.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "#X_test_reg: This is the new data (features) that the model hasn't seen before.\n",
        "#y_test_reg: This is the real answers for the new data.\n",
        "print(\"Support Vector Regressor Score:\", svr.score(X_test_reg, y_test_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIcqI3CkH6GT",
        "outputId": "053b1207-09b1-4da4-a210-f80b80be5609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Regressor Score: 0.0370706226883748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(13)K-Neighbors Classifier () =>\n",
        "-machine learning model that classifies data points based on the majority class among their closest neighbors in the feature space.\n",
        "\n",
        "-It looks at a specified number of nearby points (k) to decide which category a new data point belongs to, making it simple and effective for many classification tasks"
      ],
      "metadata": {
        "id": "c7ZpKuPYH97r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create an instance of the KNeighborsClassifier\n",
        "kn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Fit the model using the training data\n",
        "kn_classifier.fit(X_train, y_train_classification)\n",
        "\n",
        "# X_test: This is the new data (features) that the model hasn't seen before.\n",
        "# y_test_classification: This is the real answers for the new data.\n",
        "print(\"K-Nearest Neighbors Classifier Score:\", kn_classifier.score(X_test, y_test_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eqwlzOvIAeg",
        "outputId": "c35a03b7-cc7a-4e5f-eab3-4c0d87a412d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors Classifier Score: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(14) KNeighborsRegressor () =>\n",
        "-machine learning model used for predicting continuous values based on the average of the values from the nearest neighbors in the dataset.\n",
        "\n",
        "-It looks at a specified number of nearby data points (k) and predicts the target value by averaging their outputs, making it a straightforward and intuitive approach for regression tasks."
      ],
      "metadata": {
        "id": "P0tnoGN6ILpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor  # Import KNeighborsRegressor\n",
        "\n",
        "# Create an instance of the KNeighborsRegressor\n",
        "kn_regressor = KNeighborsRegressor()\n",
        "\n",
        "# Fit the model using the training data\n",
        "kn_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Evaluate the model and print the R^2 score\n",
        "print(\"K-Nearest Neighbors Regressor Score:\", kn_regressor.score(X_test_reg, y_test_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRzEx-oWISK8",
        "outputId": "efeec49d-9973-4008-b586-40bd4e159051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors Regressor Score: -0.19783655315235182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a dummy dataset\n",
        "X, y = np.random.rand(100, 5), np.random.randint(0, 2, size=100)  # Features and binary target variable\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "tPHdVtjeL6d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(15)GaussianNB () =>\n",
        "-classification model that makes predictions based on the assumption that the features (inputs) are normally distributed (like a bell curve).\n",
        "\n",
        "-It calculates the probabilities for each class and chooses the class with the highest probability, making it simple and effective for many types of data"
      ],
      "metadata": {
        "id": "T-0klXwMKHYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Gaussian Naive Bayes Classifier\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "#X_test is the data we use to test our model, and y_test is the correct answers for that data.\n",
        "#By comparing the model's predictions with y_test, we can see how well the model is doing\n",
        "print(\"GaussianNB Score:\", gnb.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7vrn8NK7Sn",
        "outputId": "1e4aa5f0-adb3-40c2-dde0-b50159bede98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GaussianNB Score: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(16)BernoulliNB () =>\n",
        "-machine learning tool used for classifying data with binary features, like yes/no or true/false.\n",
        "\n",
        "-It calculates the probability of different classes (like spam or not spam) based on the presence or absence of specific features and is often used in tasks like email filtering"
      ],
      "metadata": {
        "id": "VjJJYHwdKPcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "# Bernoulli Naive Bayes Classifier\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "#X_test is the data we use to test our model, and y_test is the correct answers for that data.\n",
        "#By comparing the model's predictions with y_test, we can see how well the model is doing\n",
        "print(\"BernoulliNB Score:\", bnb.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4iXJF4hK_tD",
        "outputId": "eab9d545-5286-4b95-883a-b2d2b97764c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BernoulliNB Score: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(17)MultinomialNB () =>\n",
        "-The MultinomialNB() function is a machine learning classifier used for text classification tasks where the features are counts or frequencies, such as the number of times a word appears in a document."
      ],
      "metadata": {
        "id": "9Wh5ONqgKTJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Multinomial Naive Bayes Classifier\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train, y_train)\n",
        "\n",
        "#X_test is the data we use to test our model, and y_test is the correct answers for that data.\n",
        "#By comparing the model's predictions with y_test, we can see how well the model is doing\n",
        "print(\"MultinomialNB Score:\", mnb.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXKMOT5ALGKX",
        "outputId": "c5f4c543-67f4-4e32-b64b-c69928f8cf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB Score: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(18)SGDClassifier () =>\n",
        "-The SGDClassifier() function is a machine learning tool that uses Stochastic Gradient Descent (SGD) for training models.\n",
        "\n",
        "-It’s particularly useful for large datasets because it updates the model incrementally, making it efficient in terms of memory and computation."
      ],
      "metadata": {
        "id": "B-lbWKo7KtSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "# Stochastic Gradient Descent Classifier\n",
        "sgd_classifier = SGDClassifier()\n",
        "sgd_classifier.fit(X_train, y_train)\n",
        "\n",
        "#X_test is the data we use to test our model, and y_test is the correct answers for that data.\n",
        "#By comparing the model's predictions with y_test, we can see how well the model is doing\n",
        "print(\"SGDClassifier Score:\", sgd_classifier.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70QIPdu2LKlo",
        "outputId": "6f99b78c-fd46-4aa2-8672-fcb8348529b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDClassifier Score: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "KgB8j-2mMz9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, precision_score, recall_score,\n",
        "    f1_score, accuracy_score, roc_curve, roc_auc_score, mean_squared_error,\n",
        "    r2_score, mean_absolute_error, explained_variance_score, log_loss,\n",
        "    brier_score_loss, make_scorer\n",
        ")\n",
        "\n",
        "# Classification dataset\n",
        "X, y_classification = np.random.rand(100, 5), np.random.randint(0, 2, size=100)\n",
        "# Regression dataset\n",
        "y_regression = np.random.rand(100)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression model for classification\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_clf, y_train_clf)\n",
        "y_pred_clf = clf.predict(X_test_clf)\n",
        "\n",
        "# Linear Regression model for regression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train_reg, y_train_reg)\n",
        "y_pred_reg = reg.predict(X_test_reg)\n"
      ],
      "metadata": {
        "id": "A05AWqgKRhY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(19)cross_val_score () =>\n",
        "-used to evaluate the performance of a machine learning model by splitting the data into multiple parts (or folds).\n",
        "\n",
        "-It trains the model on some of the folds and tests it on the remaining fold, repeating this process several times. This helps to get a more  accuracy by averaging the scores from each fold."
      ],
      "metadata": {
        "id": "dK-i3oFySjCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#clf =>  This is your classification model that you want to evaluat.\n",
        "#X_train_clf => This is the data set of your training data.\n",
        "#y_train_clf: This is the target variable (labels) corresponding to the training data.\n",
        "#cv=5: This specifies that the training data should be split into 5 equal parts (folds) for cross-validation.\n",
        "\n",
        "cv_scores_clf = cross_val_score(clf, X_train_clf, y_train_clf, cv=5)\n",
        "print(\"Cross-validation scores (classification):\", cv_scores_clf)  #This line prints the array of cross-validation scores\n",
        "\n",
        "# Fit and predict for classification\n",
        "clf.fit(X_train_clf, y_train_clf)\n",
        "\n",
        "#This line uses the trained model to make predictions on the test feature set (X_test_clf).\n",
        "#The predicted labels are stored in the variable y_pred_class.\n",
        "y_pred_class = clf.predict(X_test_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U07_J6xwSvDA",
        "outputId": "a3dd5288-b192-4964-ca93-c7b0ee777853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores (classification): [0.5    0.625  0.4375 0.4375 0.5625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(20)GridSearchCV ()=>\n",
        "-GridSearchCV() is a tool in machine learning that helps you find the best combination of parameters (settings) for your model.\n",
        "\n",
        "-It does this by testing all possible combinations of given parameters and checking which one performs the best using cross-validation, ensuring your model is accurate and reliable."
      ],
      "metadata": {
        "id": "wqT8CIMzTGIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "grid_clf.fit(X_train_clf, y_train_clf)\n",
        "print(\"Best params (GridSearchCV):\", grid_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Kj9brTzKTIXi",
        "outputId": "86bff873-5f15-4982-c1af-f8dc807a6bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grid_clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-64cb0b5e8baa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params (GridSearchCV):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(21)classification_report () =>\n",
        "-provides a summary of key metrics (precision, recall, F1-score, and support) to evaluate the performance of a classification model.\n",
        "\n",
        "-It helps you understand how well your model performed for each class in a classification task.\n"
      ],
      "metadata": {
        "id": "s_Bc66DvUNp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "\n",
        "#classification_report => This function, from the sklearn.metrics module, creates a report showing how well a classification model has performed.\n",
        "#y_test_clf => This is the list or array of true labels (the actual categories or classes) from the test dataset.\n",
        "#y_pred_clf => This is the list or array of predicted labels (the categories or classes that the model predicted for the test dataset).\n",
        "\n",
        "print(classification_report(y_test_clf, y_pred_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ivy0ihLW8Ie",
        "outputId": "671852ab-ca90-44b8-efb6-979915b67f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.38      0.50        13\n",
            "           1       0.38      0.71      0.50         7\n",
            "\n",
            "    accuracy                           0.50        20\n",
            "   macro avg       0.55      0.55      0.50        20\n",
            "weighted avg       0.60      0.50      0.50        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(22) confusion_matrix () =>\n",
        "-The confusion_matrix is a tool used to evaluate the performance of a classification model. It shows how many predictions were correctly or incorrectly classified by the model, breaking it down into four categories :\n",
        "\n",
        "-TP TN FP FN"
      ],
      "metadata": {
        "id": "ZTNcPhK2UkJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nConfusion Matrix:\")\n",
        "\n",
        "#y_test_clf: This is the list or array of true labels (the actual categories or classes) from the test dataset.\n",
        "#y_pred_clf: This is the list or array of predicted labels (the categories or classes predicted by the model for the test dataset)\n",
        "\n",
        "print(confusion_matrix(y_test_clf, y_pred_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrR3bpV8XugB",
        "outputId": "02bf3e2d-2768-4403-d252-b50d15d3ddeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "[[6 7]\n",
            " [4 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(23)Precision score() =>\n",
        "-The precision score is a metric used to evaluate the accuracy of positive predictions in classification.\n",
        "\n",
        "-checks how many of the positive predictions made by a model were actually correct. It's important when you want to avoid false alarms and make sure positive results are accurate\n",
        "\n"
      ],
      "metadata": {
        "id": "BruMGEouUxGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_clf => This is the list or array of true labels (the actual classes) from the test dataset.\n",
        "#y_pred_class => This is the list or array of predicted labels (the classes predicted by the model) for the test dataset\n",
        "\n",
        "print(\"\\nPrecision Score:\", precision_score(y_test_clf, y_pred_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEgg30V6aYb0",
        "outputId": "658efb2b-01d9-4c3e-d03b-ff0a263d1bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precision Score: 0.42857142857142855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(24)Recall Score () =>\n",
        " -Measures the model's ability to identify true positives out of all actual positives, useful when minimizing false negatives is critical."
      ],
      "metadata": {
        "id": "rLIBcIUhU-_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_clf => This is the list or array of true labels (the actual categories or classes) from the test dataset.\n",
        "#y_pred_clf => This is the list or array of predicted labels (the categories or classes predicted by the model for the test dataset)\n",
        "\n",
        "print(\"Recall Score:\", recall_score(y_test_clf, y_pred_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7zX2bmGckIC",
        "outputId": "35bb49a5-1dc3-40ab-ab1d-49da050832d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall Score: 0.2222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(25) F1 Score () =>\n",
        "-Balances precision and recall, useful when both false positives and false negatives matter."
      ],
      "metadata": {
        "id": "uNsV_ENvV7Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_clf => This is the list or array of true labels (the actual categories or classes) from the test dataset.\n",
        "#y_pred_clf => This is the list or array of predicted labels (the categories or classes predicted by the model for the test dataset)\n",
        "print(\"F1 Score:\", f1_score(y_test_clf, y_pred_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG7rzrDUcxN1",
        "outputId": "21cb88cb-9f07-48bb-e134-3c6ce7c5abb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.26666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(26)Accuracy Score () =>\n",
        " -Measures the proportion of correct predictions, but can be misleading in imbalanced datasets."
      ],
      "metadata": {
        "id": "HwYWXrhaWB0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_clf => This is the list or array of true labels (the actual categories or classes) from the test dataset.\n",
        "#y_pred_clf => This is the list or array of predicted labels (the categories or classes predicted by the model for the test dataset)\n",
        "\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test_clf, y_pred_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSZ4MUAcc182",
        "outputId": "d573d6f9-bdae-4d6d-aeda-8b426930d186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(27)Accuracy Score () =>\n",
        " -Measures the proportion of correct predictions, but can be misleading in imbalanced datasets."
      ],
      "metadata": {
        "id": "0MneiXJjWJ2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_clf: This is the list or array of true labels (the actual categories or classes) from the test dataset.\n",
        "#y_pred_clf: This is the list or array of predicted labels (the categories or classes predicted by the model for the test dataset).\n",
        "\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test_clf, y_pred_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxfW66tEc8Kc",
        "outputId": "b8dbea6a-8ec8-4f4e-c7cc-6f6a6ba2560c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(28)R² Score () =>\n",
        "-It's useful for assessing the quality of the model—higher values indicate a better fit to the data."
      ],
      "metadata": {
        "id": "x7sXb6LTWQsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_reg: This is the list or array of true values (the actual outcomes) from the test dataset.\n",
        "#y_pred_reg: This is the list or array of predicted values (the outcomes predicted by the model) for the test dataset.\n",
        "\n",
        "print(\"R^2 Score:\", r2_score(y_test_reg, y_pred_reg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC-wkLdDdFeQ",
        "outputId": "b6e532b4-05b8-491f-a2c5-4c5f1063a1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 Score: -0.15161108239164256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(29)Mean Absolute Error (MAE) =>\n",
        " -Measures the average absolute difference between predicted and actual values, less sensitive to outliers than MSE."
      ],
      "metadata": {
        "id": "8S8LotfsWWfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_reg => This is the list or array of true values (the actual outcomes) from the test dataset.\n",
        "#y_pred_reg => This is the list or array of predicted values (the outcomes predicted by the model) for the test dataset.\n",
        "\n",
        "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_reg, y_pred_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYcRXpnGdVZ8",
        "outputId": "0c488882-7dc4-48a6-d583-fefb056d30d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.22254696210376027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(30)Explained Variance Score () =>\n",
        " -Measures the proportion of variance explained by the model, indicating the model’s performance."
      ],
      "metadata": {
        "id": "_qGvmxm4Wfcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test_reg => This is the list or array of true values (the actual outcomes) from the test dataset.\n",
        "#y_pred_reg => This is the list or array of predicted values (the outcomes predicted by the model) for the test dataset.\n",
        "\n",
        "print(\"Explained Variance Score:\", explained_variance_score(y_test_reg, y_pred_reg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B34_M6GCdZLv",
        "outputId": "d53905bf-1727-4267-cc3b-89454e7d09b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Score: -0.13179928754049675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(31)StandardScaler(): =>\n",
        "-standardizes the features of your dataset. It transforms the data so that it has a mean of 0 and a standard deviation of 1."
      ],
      "metadata": {
        "id": "5wvUM-0QH_T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data = [[1, 2], [3, 4], [5, 6]]\n",
        "\n",
        "#Fit => It calculates the mean and standard deviation for each feature in the data.\n",
        "#Transform => It standardizes the data by subtracting the mean and dividing by the standard deviation for each feature.\n",
        "\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(\"Standard Scaled Data:\\n\", scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN387pn4JV1c",
        "outputId": "761a45d3-e080-427e-dbd7-4f62a4469a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard Scaled Data:\n",
            " [[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(32)MinMaxScaler() =>\n",
        "-scales the features of your data to a specific range, usually between 0 and 1. This helps ensure that all features have the same importance, which can improve the performance of some machine learning models."
      ],
      "metadata": {
        "id": "I8EO_apRIMl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = [[1, 2], [3, 4], [5, 6]]\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(\"Min-Max Scaled Data:\\n\", scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iyeB2t0JeYT",
        "outputId": "f946d83a-f706-45e7-9681-7cb32d124a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min-Max Scaled Data:\n",
            " [[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(33)MaxAbsScaler() =>\n",
        " -Scales each feature by its maximum absolute value, preserving sparsity and scaling the data within the range of [-1, 1]."
      ],
      "metadata": {
        "id": "b0xpDMCEIR2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = [[1, 2], [3, 4], [5, 6]]\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(\"Min-Max Scaled Data:\\n\", scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hnBDS5pJiaP",
        "outputId": "e53a77c5-5678-4cb5-ebc6-0e04d1faeabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min-Max Scaled Data:\n",
            " [[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(34)RobustScaler() =>\n",
        " -Scales features using statistics that are robust to outliers, specifically by removing the median and scaling according to the interquartile range (IQR)."
      ],
      "metadata": {
        "id": "VhmPPXWMIW4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "data = [[1, 2], [3, 4], [5, 6], [100, 200]]\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(\"Robust Scaled Data:\\n\", scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJuhNSRKJ4e_",
        "outputId": "46ce6963-bac6-468e-ab43-4608dae3e35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robust Scaled Data:\n",
            " [[-0.11428571 -0.05882353]\n",
            " [-0.03809524 -0.01960784]\n",
            " [ 0.03809524  0.01960784]\n",
            " [ 3.65714286  3.82352941]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(35)Normalizer() =>\n",
        " -Scales individual samples to have a unit norm (length), transforming each sample to lie on the hypersphere of radius 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "9OMkbJrzIedf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "normalizer = Normalizer()\n",
        "data = [[1, 2], [3, 4], [5, 6]]\n",
        "normalized_data = normalizer.fit_transform(data)\n",
        "print(\"Normalized Data:\\n\", normalized_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGpNvL2UJ_ih",
        "outputId": "d1c492f7-bb9b-40b3-b221-fe8412ebf86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Data:\n",
            " [[0.4472136  0.89442719]\n",
            " [0.6        0.8       ]\n",
            " [0.6401844  0.76822128]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(36)Binarizer() =>\n",
        " -Converts numerical features into binary values (0 or 1) based on a specified threshold, turning any value above the threshold into 1 and below into 0"
      ],
      "metadata": {
        "id": "7TspAb2qIjny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "#Binarizer => This is a class in the sklearn library that is used to convert numerical data into binary values (0s and 1s) based on a specified threshold.threshold=3.0:\n",
        "#This sets the threshold value at 3.0. It means that any value in the data that is greater than or equal to 3.0 will be converted to 1, and any value that is less than 3.0 will be converted to 0.\n",
        "\n",
        "binarizer = Binarizer(threshold=3.0)\n",
        "data = [[1, 2], [3, 4], [5, 6]]\n",
        "binary_data = binarizer.fit_transform(data)\n",
        "print(\"Binarized Data:\\n\", binary_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5eaD_DsKD_U",
        "outputId": "633f118a-d4a5-47ec-e567-fa3227de4e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binarized Data:\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(37)PolynomialFeatures() =>\n",
        " Generates polynomial and interaction features from the original features, allowing for the inclusion of non-linear relationships in linear models."
      ],
      "metadata": {
        "id": "dUR164zIIuXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "#the program to create new features based on your original features, using mathematical powers up to 2.\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "data = [[1, 2], [3, 4]]\n",
        "poly_data = poly.fit_transform(data)\n",
        "print(\"Polynomial Features:\\n\", poly_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E1JK-Z9KHrT",
        "outputId": "b62fe5b9-88b2-4e19-b34a-b27220d4bca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Features:\n",
            " [[ 1.  1.  2.  1.  2.  4.]\n",
            " [ 1.  3.  4.  9. 12. 16.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(38)OneHotEncoder() =>\n",
        " -Converts categorical variables into a format that can be provided to ML algorithms to do a better job in prediction, creating binary columns for each category.\n",
        "\n",
        " -it require numerical input, and this encoding helps represent categories without implying any ordinal relationship between them"
      ],
      "metadata": {
        "id": "syQua-y9IzTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "data = [[0], [1], [2]]\n",
        "encoded_data = encoder.fit_transform(data).toarray()\n",
        "print(\"One-Hot Encoded Data:\\n\", encoded_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1NC9H0dKMQo",
        "outputId": "850dd70f-6399-4350-9c40-d337eff99182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoded Data:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(39)LabelEncoder() =>\n",
        " -Converts categorical labels into integer values, providing a way to represent categories numerically for ML algorithms."
      ],
      "metadata": {
        "id": "go3bhIBWJGt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "data = ['cat', 'dog', 'cat', 'bird']\n",
        "encoded_labels = encoder.fit_transform(data)\n",
        "print(\"Label Encoded Data:\\n\", encoded_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX7R4muIKSDk",
        "outputId": "29d2d6c0-e2ec-46d0-f0f3-7b1a9276fbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoded Data:\n",
            " [1 2 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(40)OrdinalEncoder() =>\n",
        " -Encodes categorical features as ordinal integers, maintaining the order of categories, which is useful for ordinal data."
      ],
      "metadata": {
        "id": "BiDhC7zlJLdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "data = [['cat'], ['dog'], ['bird']]\n",
        "encoded_data = encoder.fit_transform(data)\n",
        "print(\"Ordinal Encoded Data:\\n\", encoded_data)\n"
      ],
      "metadata": {
        "id": "N7BgltBcKaM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(41)SimpleImputer() =>\n",
        " Fills in missing values in datasets using a specified strategy (mean, median, most frequent, or constant) for imputation."
      ],
      "metadata": {
        "id": "UV8GN1miKch6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data = [[1, 2], [None, 3], [7, 6]]\n",
        "imputed_data = imputer.fit_transform(data)\n",
        "print(\"Imputed Data:\\n\", imputed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Razy46dAK_v5",
        "outputId": "4de13a99-f4e9-4692-9e9e-c5c7e4aa3c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputed Data:\n",
            " [[1. 2.]\n",
            " [4. 3.]\n",
            " [7. 6.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(42)KNNImputer() =>\n",
        " Imputes missing values by using the k-nearest neighbors algorithm, filling in missing values based on the mean of the nearest neighbors."
      ],
      "metadata": {
        "id": "CR4VhtoNKrGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "data = [[1, 2], [None, 3], [7, 6]]\n",
        "imputed_data = imputer.fit_transform(data)\n",
        "print(\"KNN Imputed Data:\\n\", imputed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3iL5L-7K7nt",
        "outputId": "eccbbcb5-52ba-4b73-ed57-da1a95530706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Imputed Data:\n",
            " [[1. 2.]\n",
            " [4. 3.]\n",
            " [7. 6.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(43)PowerTransformer() =>\n",
        " Applies a power transformation to make data more Gaussian-like, which can help improve the performance of machine learning algorithms."
      ],
      "metadata": {
        "id": "qYGNtuo_KwR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "transformer = PowerTransformer()\n",
        "data = [[1, 2], [3, 4], [5, 6]]\n",
        "transformed_data = transformer.fit_transform(data)\n",
        "print(\"Power Transformed Data:\\n\", transformed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUjozh-1K5R2",
        "outputId": "e1fb419a-b59f-447b-9198-00040f8a61d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Power Transformed Data:\n",
            " [[-1.26755013 -1.25808855]\n",
            " [ 0.09064754  0.06966078]\n",
            " [ 1.17690259  1.18842777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(44)QuantileTransformer() =>\n",
        "Transforms features to follow a uniform or normal distribution. This is especially useful for handling outliers."
      ],
      "metadata": {
        "id": "KqWcT2K4MLa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "transformer = QuantileTransformer(output_distribution='normal')\n",
        "data = [[1], [2], [3], [4], [5]]\n",
        "transformed_data = transformer.fit_transform(data)\n",
        "print(\"Quantile Transformed Data:\\n\", transformed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D_sRQZGMR9s",
        "outputId": "14e11020-e609-4b65-aa16-90f4fc76b336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile Transformed Data:\n",
            " [[-5.19933758]\n",
            " [-0.67448975]\n",
            " [ 0.        ]\n",
            " [ 0.67448975]\n",
            " [ 5.19933758]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(45)LabelBinarizer() =>\n",
        "Binarizes labels in a multi-class setting, encoding them as binary arrays."
      ],
      "metadata": {
        "id": "Nyk02Q6nMqKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "binarizer = LabelBinarizer()\n",
        "data = ['cat', 'dog', 'cat', 'bird']\n",
        "binarized_data = binarizer.fit_transform(data)\n",
        "print(\"Label Binarized Data:\\n\", binarized_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwfCHjuIMzV3",
        "outputId": "5b957020-6bca-443c-fc20-f5de46238024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Binarized Data:\n",
            " [[0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(46)add_dummy_feature() =>\n",
        "Adds a column of ones to the input data (useful for linear regression to account for the intercept)."
      ],
      "metadata": {
        "id": "iAtUvgjZM4FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import add_dummy_feature\n",
        "\n",
        "data = [[1], [2], [3]]\n",
        "dummy_data = add_dummy_feature(data)\n",
        "print(\"Data with Dummy Feature:\\n\", dummy_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L9l5CuqM85B",
        "outputId": "a29576c7-1f6a-4728-afc9-cd2dfa4c7f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with Dummy Feature:\n",
            " [[1. 1.]\n",
            " [1. 2.]\n",
            " [1. 3.]]\n"
          ]
        }
      ]
    }
  ]
}